import numpy as np
import pandas as pd
df = pd.read_csv('CAR DETAILS.csv')
df.head()
df.shape
df.info()
df.duplicated().sum()
df.isnull().sum()
df.dtypes

print(df[["year", "selling_price", "km_driven"]].describe())

df = df.drop('name', axis=1)

import matplotlib.pyplot as plt
import seaborn as sns


plt.figure(figsize=(8, 6))
sns.countplot(data=df, x="owner")
plt.title("Distribution of Owners")
plt.xlabel("Owner Type")
plt.ylabel("Count")
plt.show()


plt.figure(figsize=(8, 6))
sns.histplot(df["km_driven"], bins=20, kde=True)
plt.title("Distribution of Kilometers Driven")
plt.xlabel("Kilometers Driven")
plt.ylabel("Count")
plt.show()


sns.histplot(df["year"], bins=10, kde=True)
plt.title("Distribution of Years")
plt.xlabel("Year")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(8, 6))
sns.histplot(df["selling_price"], bins=20, kde=True)
plt.title("Distribution of Selling Prices")
plt.xlabel("Selling Price")
plt.ylabel("Count")
plt.show()


plt.figure(figsize=(8, 6))
sns.countplot(data=df, x="fuel")
plt.title("Distribution of Fuel Types")
plt.xlabel("Fuel Type")
plt.ylabel("Count")
plt.show()


plt.figure(figsize=(8, 6))
sns.countplot(data=df, x="seller_type")
plt.title("Distribution of Seller Types")
plt.xlabel("Seller Type")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(8, 6))
sns.countplot(data=df, x="transmission")
plt.title("Distribution of Transmission Types")
plt.xlabel("Transmission Type")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(8, 6))
sns.scatterplot(data=df, x="year", y="selling_price")
plt.title("Correlation between Selling Price and Year")
plt.xlabel("Year")
plt.ylabel("Selling Price")
plt.show()


plt.scatter(df["km_driven"], df["selling_price"])
plt.title("Selling Price vs. Kilometers Driven")
plt.xlabel("Kilometers Driven")
plt.ylabel("Selling Price")
plt.show()

plt.figure(figsize=(8, 6))
plt.bar(df["transmission"],df["selling_price"])
plt.title("Selling Price by Transmission Type")
plt.xlabel("Transmission Type")
plt.ylabel("Average Selling Price")
plt.show()


plt.figure(figsize=(8, 6))
plt.bar(df["fuel"], df["selling_price"])
plt.title("Selling Price by Fuel Type")
plt.xlabel("Fuel Type")
plt.ylabel("Average Selling Price")
plt.show()

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

categorical_columns = ["fuel", "seller_type", "transmission", "owner"]
for column in categorical_columns:
    df[column] = label_encoder.fit_transform(df[column])


print(df.head())


from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import Ridge, Lasso, LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


# Separate the features (X) and target variable (y)
X = df.drop("selling_price", axis=1)
y = df["selling_price"]


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


reg = LinearRegression()

reg.fit(X_train, y_train)



y_pred = reg.predict(X_test)



print("MSE => ", mean_squared_error(y_test, y_pred))
print("R2 Score => ",r2_score(y_test, y_pred))



las = Lasso()



las.fit(X_train,y_train)


y_pred = las.predict(X_test)
print("MSE => ", mean_squared_error(y_test, y_pred))
print("R2 Score => ",r2_score(y_test, y_pred))


rid = Ridge()


rid.fit(X_train,y_train)



y_pred = rid.predict(X_test)
print("MSE => ", mean_squared_error(y_test, y_pred))
print("R2 Score => ",r2_score(y_test, y_pred))


from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.ensemble import AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import BaggingRegressor
from sklearn.ensemble import AdaBoostClassifier



def evaluate_model(model, X_test, y_test):
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test,y_pred)
        cm = confusion_matrix(y_test, y_pred)
        report = classification_report(y_test, y_pred)
        return accuracy, cm, report


logreg = LogisticRegression()
logreg.fit(X_train, y_train)



logreg_accuracy, logreg_cm, logreg_report = evaluate_model(logreg, X_test, y_test)



print("Logistic Regression")
print("Accuracy:", logreg_accuracy)
print("Confusion Matrix:")
print(logreg_cm)
print("Classification Report:")
print(logreg_report)
print("\n")



dt_classifier = DecisionTreeClassifier()
dt_classifier.fit(X_train, y_train)



dt_accuracy, dt_cm, dt_report = evaluate_model(dt_classifier, X_test, y_test)

print("Decision Tree Classifier")
print("Accuracy:", dt_accuracy)
print("Confusion Matrix:")
print(dt_cm)
print("Classification Report:")
print(dt_report)
print("\n")


rf_classifier = RandomForestClassifier()
rf_classifier.fit(X_train, y_train)


rf_accuracy, rf_cm, rf_report = evaluate_model(rf_classifier, X_test, y_test)


print("Random Forest Classifier")
print("Accuracy:", rf_accuracy)
print("Confusion Matrix:")
print(rf_cm)
print("Classification Report:")
print(rf_report)
print("\n")

knn_classifier = KNeighborsClassifier()
knn_classifier.fit(X_train, y_train)



knn_accuracy, knn_cm, knn_report = evaluate_model(knn_classifier, X_test, y_test)



print("K-Nearest Neighbors (KNN) Classifier")
print("Accuracy:", knn_accuracy)
print("Confusion Matrix:")
print(knn_cm)
print("Classification Report:")
print(knn_report)
print("\n")



bagging = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)
bagging.fit(X_train, y_train)




y_pred = bagging.predict(X_test)



mse = mean_squared_error(y_test, y_pred)

print("Bagging Regression")
print("Mean Squared Error:", mse)



bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)
bagging.fit(X_train, y_train)

y_pred = bagging.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

print("Bagging Classification")
print("Accuracy:", accuracy)


adaboost = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)
adaboost.fit(X_train, y_train)


y_pred = adaboost.predict(X_test)


mse = mean_squared_error(y_test, y_pred)

print("AdaBoost Regression")
print("Mean Squared Error:", mse)

adaboost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)
adaboost.fit(X_train, y_train)

y_pred = adaboost.predict(X_test)



print("AdaBoost Classification")
print("Accuracy:", accuracy)


import pickle


pickle.dump(rf_classifier,open('rf_classifier.pkl','wb'))

pickle.dump(dt_classifier, open('dt_classifier.pkl', 'wb'))

new_dataset = df.sample(n=20, random_state=42)
new_dataset.head()
loaded_model = pickle.load(open('dt_classifier.pkl', 'rb'))
X_new = new_dataset.drop("selling_price", axis=1)
y_pred = loaded_model.predict(X_new)
y_actual = new_dataset["selling_price"]
print("Predicted Values:\n", y_pred)
print("Actual Values:\n", y_actual)